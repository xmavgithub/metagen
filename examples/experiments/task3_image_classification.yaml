# Task 3: Image Classification
# Vision Transformer for image classification
# Tests: image modality, ViT architecture

name: "vit-classifier"
description: "Vision Transformer for image classification experiments"

modality:
  inputs: ["image"]
  outputs: ["text"]

architecture:
  family: "transformer"
  variant: "encoder-only"
  attention: "full"
  context_length: 197  # 196 patches + 1 CLS token

constraints:
  parameters: "86M"
  latency: "15ms"
  device: "gpu"
  image_size: 224
  patch_size: 16

training:
  objective: ["cross_entropy"]
  optimizer: "adamw"
  scheduler: "cosine"
  batch_size: 64
  epochs: 30

evaluation:
  benchmarks: ["accuracy", "top5_accuracy"]
  datasets: ["synthetic_imagenet"]
